{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Series de tiempo con FB Prophet\n",
    "\n",
    "Una buena fuente de documentación es:\n",
    "https://www.digitalocean.com/community/tutorials/a-guide-to-time-series-forecasting-with-prophet-in-python-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "from numpy import array\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from pandas import read_csv\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from matplotlib import pyplot\n",
    "%matplotlib inline  \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from prophet import Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def parse_date (x): \n",
    "    return datetime.datetime.strptime(\"0\"+str(x), '%y-%m') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def medir_rmse(actual, predicho):\n",
    "    return sqrt(mean_squared_error(actual, predicho))\n",
    "\n",
    "#measure_rmse([1,2],[1,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def division_entreno_prueba(datos, n_entreno):\n",
    "    entreno = datos.iloc[:n_entreno]\n",
    "    prueba = datos.iloc[n_entreno:]\n",
    "    return entreno, prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prediccion_prophet(series):\n",
    "    series.head()\n",
    "    modelo = Prophet(mcmc_samples = 500, seasonality_mode = 'multiplicative').fit(series);\n",
    "    futuro = modelo.make_future_dataframe(periods = 1,freq = 'M')\n",
    "    predicciones = modelo.predict(futuro)\n",
    "    return predicciones.iloc[-1][\"yhat\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validación hacia el frente para datos univariados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def validacion_al_frente(datos, n_entreno, cfg):\n",
    "    predicciones = []\n",
    "    # dividir el conjunto de datos\n",
    "    entreno, prueba = division_entreno_prueba(datos, n_entreno)\n",
    "    # grabar la historia con el conjunto de datos de entrenamiento\n",
    "    historia = entreno\n",
    "    # pasar por cada incremento de tiempo en el conjunto de prueba\n",
    "    for i in range(len(prueba)):\n",
    "        # ajustar el modelo a los datos y predecir los datos históricos\n",
    "        yhat = prediccion_prophet(historia)\n",
    "        # agregar el dato predicho en la lista de preducciones\n",
    "        predicciones.append(yhat)\n",
    "        # agregar la observación a la historia para la siguiente iteración\n",
    "        historia.append(pd.DataFrame(prueba.iloc[i]))\n",
    "    # estimar el error de las predicciones\n",
    "    error = medir_rmse(prueba[\"y\"], predicciones)\n",
    "    return [error, predicciones]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluar_modelo(datos, n_entreno, metodo, cfg, debug = False):\n",
    "    resultado = None\n",
    "    predicciones = None\n",
    "    # convertir config a una llave\n",
    "    llave = str(cfg)\n",
    "    resultado, predicciones = validacion_al_frente(datos, n_entreno, metodo, cfg)\n",
    "    if resultado is not None:\n",
    "        print(f' > Modelo[{llave}] {resultado:.3f}')\n",
    "    return (llave, resultado, predicciones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def buscar_mejor_solucion(series, nombre, metodo = \"prophet\"):    \n",
    "    datos = series\n",
    "\n",
    "    resultados = []\n",
    "    # división de datos\n",
    "    n_entreno = int(len(datos)*0.8) # porcentaje usado para entrenar\n",
    "    long_max = len(datos) - n_entreno\n",
    "    print(f\"Tamaño entreno {n_entreno} \")\n",
    "    print(f\"Tamaño prueba {long_max}\")\n",
    "    lista_cfg = [1]\n",
    "    \n",
    "    resultados = [evaluar_modelo(datos, n_entreno, metodo, cfg) for cfg in lista_cfg]\n",
    "    \n",
    "    # ordenar configs por error, ascendente\n",
    "    resultados.sort(key=lambda tup: tup[1])\n",
    "\n",
    "\n",
    "    print('terminado')\n",
    "    # listar las tres configuraciones mejores\n",
    "    for cfg, error, predicciones in resultados[:3]:\n",
    "        print(cfg, error)\n",
    "\n",
    "    \n",
    "    #desplegar\n",
    "    entreno, prueba = division_entreno_prueba(datos,n_entreno)\n",
    "    prediccion = pd.DataFrame(list(entreno[\"y\"]) + resultados[0][2])\n",
    "    \n",
    "    #####\n",
    "    datos.set_index(['ds'],inplace=True)\n",
    "    #prediccion.set_index(['ds'],inplace = True)\n",
    "    prediccion.index = datos.index\n",
    "\n",
    "\n",
    "    ax = pd.DataFrame(datos).plot(label=\"Original\") # datos originales\n",
    "    prediccion.plot(ax=ax, alpha=.7, figsize=(14,7))\n",
    "    plt.savefig(f\"{nombre}_{metodo}.png\")\n",
    "    plt.show()\n",
    "    return [datos,prediccion]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluar_prediccion(series, frecuencia = \"M\"):\n",
    "    datos = series\n",
    "    n_entreno = int(len(datos) * 0.8) # porcentaje usado para entreno\n",
    "    long_max = len(datos) - n_entreno\n",
    "    print(f\"Tamaño entreno {n_entreno} \")\n",
    "    print(f\"Tamaño prueba {long_max} \")\n",
    "    lista_cfg = [1]\n",
    "    entreno, prueba = division_entreno_prueba(datos, n_entreno)\n",
    "    modelo = Prophet(mcmc_samples = 500, seasonality_mode = 'multiplicative').fit(series);\n",
    "    futuro = modelo.make_future_dataframe(periods = len(prueba),freq = frecuencia)\n",
    "    predicciones = modelo.predict(futuro)\n",
    "    modelo.plot(predicciones)\n",
    "    rmse = medir_rmse(predicciones.iloc[len(entreno):len(series)][\"yhat\"], prueba[\"y\"])\n",
    "    print(f\"RMSE: {rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluación multi-pasos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nacimientos Niñas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "series = pd.read_csv('daily-total-female-births.csv', header=0, index_col=None)\n",
    "series['ds']  = pd.to_datetime(series['Date'])\n",
    "series[['y']] = series[['Births']].astype(float)\n",
    "series = series[[\"ds\",\"y\"]]\n",
    "series.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "series = pd.read_csv('daily-total-female-births.csv', header=0, index_col=None)\n",
    "series['ds']  = pd.to_datetime(series['Date'])\n",
    "series[['y']] = series[['Births']].astype(float)\n",
    "series = series[[\"ds\",\"y\"]]\n",
    "evaluar_prediccion(series, \"D\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shampoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "series = pd.read_csv('shampoo.csv', header=0)\n",
    "series['ds']  = series['Month'].apply(lambda x: parse_date(x))\n",
    "series[['y']] = series[['Sales']].astype(float)\n",
    "series = series[[\"ds\",\"y\"]]\n",
    "evaluar_prediccion(series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temperaturas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "series = pd.read_csv('monthly-mean-temp.csv', header=0, index_col=None)\n",
    "series['ds']  = pd.to_datetime(series['Month'])\n",
    "series[['y']] = series[['Temperature']].astype(float)\n",
    "series = series[[\"ds\",\"y\"]]\n",
    "evaluar_prediccion(series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ventas de carros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "series = pd.read_csv('monthly-car-sales.csv', header=0,parse_dates=[\"Month\"])\n",
    "series['ds']  = series['Month']\n",
    "series[['y']] = series[['Sales']].astype(float)\n",
    "series = series[[\"ds\",\"y\"]]\n",
    "evaluar_prediccion(series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluación paso a paso (TODO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "series = pd.read_csv('monthly-car-sales.csv', header=0, index_col=None)\n",
    "series['ds']  = pd.to_datetime(series['Month'])\n",
    "series[['y']] = series[['Sales']].astype(float)\n",
    "series = series[[\"ds\",\"y\"]]\n",
    "evaluar_prediccion(series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "series = pd.read_csv('monthly-car-sales.csv', header = 0, index_col = None)\n",
    "series['ds']  = pd.to_datetime(series['Month'])\n",
    "series[['y']] = series[['Sales']].astype(float)\n",
    "series = series[[\"ds\",\"y\"]]\n",
    "series.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ajustar con Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Python\n",
    "#modelo = Prophet()\n",
    "modelo = Prophet(mcmc_samples = 500, seasonality_mode = 'multiplicative').fit(series);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predecir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "series.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "futuro = modelo.make_future_dataframe(periods = 48, freq = \"M\")\n",
    "predicciones = modelo.predict(futuro)\n",
    "predicciones[[\"ds\", \"yhat\", \"yhat_lower\", \"yhat_upper\"]].tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "modelo.plot(predicciones)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mostrar los componentes estacionales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "modelo.plot_components(predicciones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from prophet.diagnostics import cross_validation\n",
    "df_cv = cross_validation(modelo, horizon = '180 days')\n",
    "df_cv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from prophet.diagnostics import performance_metrics\n",
    "df_p = performance_metrics(df_cv)\n",
    "df_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from prophet.plot import plot_cross_validation_metric\n",
    "fig = plot_cross_validation_metric(df_cv, metric = 'mape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
