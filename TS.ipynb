{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Series de Tiempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from Def_funciones import *\n",
    "\n",
    "import pandas as pd\n",
    "from numpy import mean\n",
    "from numpy import median\n",
    "from numpy import array\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot\n",
    "import random\n",
    "from math import sqrt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "#\n",
    "from warnings import catch_warnings\n",
    "from warnings import filterwarnings\n",
    "\n",
    "# La librería statsmodel tiene implementaciones de SARIMA y de Holt-Winters\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "\n",
    "# Si el computador tiene procesadores múltiples, se aprovecharán\n",
    "#from multiprocessing import cpu_count\n",
    "\n",
    "from multiprocess import cpu_count\n",
    "from joblib import Parallel\n",
    "\n",
    "from joblib import delayed\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Métodos (funciones vistas en clase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def division_entreno_prueba(datos, n_prueba):\n",
    "    return datos[:-n_prueba], datos[-n_prueba:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def medir_rmse(actual, predicho):\n",
    "    return sqrt(mean_squared_error(actual, predicho))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validación \"walk-forward\" para datos univariados\n",
    "def validacion_al_frente(datos, n_prueba, metodo, cfg):\n",
    "    predicciones = []\n",
    "    # dividir el conjunto de datos\n",
    "    entreno, prueba = division_entreno_prueba(datos, n_prueba)\n",
    "    # grabar la historia con el conjunto de datos de entrenamiento\n",
    "    historia = [x for x in entreno]\n",
    "    # pasar por cada incremento de tiempo en el conjunto de prueba\n",
    "    for i in range(len(prueba)):\n",
    "        # ajustar el modelo a los datos y predecir los datos históricos\n",
    "        if metodo == \"promedio\":\n",
    "            yhat = prediccion_promedio(historia, cfg)\n",
    "        elif metodo == \"sarima\":\n",
    "            yhat = prediccion_sarima(historia, cfg)\n",
    "        elif metodo == \"exp\":\n",
    "            yhat = prediccion_alisamiento_exp(historia, cfg)\n",
    "        # agregar el dato predicho en la lista de preducciones\n",
    "        predicciones.append(yhat)\n",
    "        # agregar la observación a la historia para la siguiente iteración\n",
    "        historia.append(prueba[i])\n",
    "    # estimar el error de las predicciones\n",
    "    error = medir_rmse(prueba, predicciones)\n",
    "    return [error, predicciones]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def busqueda_malla(datos, lista_cfg, n_prueba, metodo = \"sarima\", paralelo = True):\n",
    "    resultados = None\n",
    "    if paralelo:\n",
    "        # ejecutar las configuraciones en paralelo\n",
    "        executor = Parallel(n_jobs = cpu_count(), backend = 'multiprocessing') \n",
    "        tareas = (delayed(calificar_modelo)(datos, n_prueba, metodo, cfg) for cfg in lista_cfg) \n",
    "        resultados = executor(tareas)\n",
    "    else:\n",
    "        resultados = [calificar_modelo(datos, n_prueba, metodo, cfg) for cfg in lista_cfg]\n",
    "    # eliminar resultados vacíos\n",
    "    resultados = [r for r in resultados if r[1] != None]\n",
    "    return resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calificar_modelo(datos, n_prueba, metodo, cfg, debug = False):\n",
    "    resultado = None\n",
    "    predicciones = None\n",
    "    # convertir la confiuración a una llave\n",
    "    llave = str(cfg)\n",
    "    if debug:\n",
    "        resultado, predicciones = validacion_al_frente(datos, n_prueba, metodo, cfg)\n",
    "    else:\n",
    "        # una falla durante la validación del modelo sugiere una configuración inestable\n",
    "        try:\n",
    "        # nunca mostrar advertencias cuando se busca en malla...demasiado \"ruido\"\n",
    "            with catch_warnings():\n",
    "                filterwarnings(\"ignore\")\n",
    "                resultado, predicciones = validacion_al_frente(datos, n_prueba, metodo, cfg)\n",
    "        except:\n",
    "            error = None\n",
    "    if resultado is not None:\n",
    "        print(f' > Modelo{llave} {resultado:.3f}')\n",
    "    return (llave, resultado, predicciones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encontrar_mejor_solucion(series, nombre, metodo = \"sarima\", muestra = False):\n",
    "    datos = series.values\n",
    "    resultados = []\n",
    "    # dividir los datos\n",
    "    n_prueba = int(len(datos) * 0.2) # porcenta usado para prueba\n",
    "    long_max = len(datos) - n_prueba\n",
    "    print(f\"Tamaño Entrenamiento {long_max}\")\n",
    "    print(f\"Tamaño Prueba {n_prueba}\")\n",
    "\n",
    "    # configuraciones de los modelos\n",
    "    if metodo == \"sarima\":\n",
    "        print(f\"Encontrando la mejor solución para {metodo}\")\n",
    "        lista_cfg = config_sarima()\n",
    "    elif metodo == \"promedio\":\n",
    "        print(f\"Encontrando la mejor solución para {metodo}\")\n",
    "        lista_cfg = config_simple(long_max)\n",
    "    elif metodo == \"exp\":\n",
    "        print(f\"Encontrando la mejor solución para {metodo}\")\n",
    "        lista_cfg = config_alisamiento_exp()\n",
    "        datos = datos[:,0]\n",
    "    # muestrear algunos\n",
    "    if muestra:\n",
    "        lista_cfg_azar = random.sample(lista_cfg, k = 25)\n",
    "        while len(resultados) < 5:\n",
    "            lista_cfg_azar = random.sample(lista_cfg, k = 25)\n",
    "            resultados += busqueda_malla(datos, lista_cfg_azar, n_prueba, metodo)\n",
    "    else:\n",
    "        # búsqueda en malla\n",
    "        resultados = busqueda_malla(datos, lista_cfg, n_prueba, metodo)\n",
    "        \n",
    "    \n",
    "    # ordenan las configuraciones por error, ascendente\n",
    "    resultados.sort(key = lambda tup: tup[1])\n",
    "\n",
    "\n",
    "    print('terminado')\n",
    "    # listar las mejores 3 configuraciones\n",
    "    for cfg, error, predicciones in resultados[:3]:\n",
    "        print(cfg, error)\n",
    "\n",
    "    # desplegar\n",
    "    entreno, prueba = division_entreno_prueba(datos, n_prueba)\n",
    "    prediccion = pd.DataFrame(list(entreno.flatten()) + resultados[0][2])\n",
    "    ax = pd.DataFrame(datos).plot(label = \"Original\") # Datos originales\n",
    "    prediccion.plot(ax = ax, alpha = .7, figsize = (14,7))\n",
    "    # Esconder las líneas de malla de la gráfica\n",
    "    # ax.grid(False)\n",
    "\n",
    "    # Esconder las marcas en los ejes\n",
    "    #ax.set_xticks([])\n",
    "    #ax.set_yticks([])\n",
    "    \n",
    "    plt.savefig(f\"{nombre}_{metodo}.png\", transparent = True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicción Promedio (Simple) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def config_simple(long_max, offsets = [1]):\n",
    "    configs = []\n",
    "    for i in range(1, long_max + 1):\n",
    "        for t in ['mediana',\"promedio\"]:\n",
    "            cfg = [i, t]\n",
    "            configs.append(cfg)\n",
    "    return configs\n",
    "\n",
    "# prediccion de un paso por promedio\n",
    "def prediccion_promedio(historia, config):\n",
    "    n, tipo_promedio = config\n",
    "    if tipo_promedio == 'promedio':\n",
    "        return mean(historia[-n:])\n",
    "    return median(historia[-n:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejemplo \"simplón\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mostrar al algoritmo siempre un conjunto más del conjunto prueba y dejar que prediga el siguiente, en forma iterativa.  Luego comparar la predicción entera al conjunto de prueba utilizando el error cuadrado medio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "series = pd.read_csv('daily-total-female-births.csv', header=0, index_col=0)\n",
    "datos = series.values\n",
    "n_prueba = 100\n",
    "long_max = len(datos) - n_prueba\n",
    "cfg = config_simple(long_max)[1]\n",
    "entreno = datos[:-n_prueba]\n",
    "prueba = datos[-n_prueba:]\n",
    "historia = [x for x in entreno]    \n",
    "predicciones = []\n",
    "for i in range(len(prueba)):\n",
    "    yhat = prediccion_promedio(historia, cfg)\n",
    "    predicciones.append(yhat)\n",
    "    historia.append(prueba[i])\n",
    "\n",
    "error = sqrt(mean_squared_error(prueba, predicciones))\n",
    "error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicción SARIMA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediccion_sarima(historia, config):\n",
    "    orden, orden_estacional, tendencia = config\n",
    "    # definir el modelo\n",
    "    modelo = SARIMAX(historia, order = orden, seasonal_order = orden_estacional, trend = tendencia,\n",
    "      enforce_stationarity = False, enforce_invertibility = False)\n",
    "    # ajustar el model con los datos\n",
    "    modelo_ajustado = modelo.fit(disp = False)\n",
    "    # hacer la predicción de un paso\n",
    "    yhat = modelo_ajustado.predict(len(historia), len(historia))\n",
    "    return yhat[0]\n",
    "\n",
    "def config_sarima(estacional = [0]):\n",
    "    modelos = []\n",
    "    # definir las listas de configuración\n",
    "    p_params = [0, 1, 2]\n",
    "    d_params = [0, 1]\n",
    "    q_params = [0, 1, 2]\n",
    "    t_params = ['n','c','t','ct'] \n",
    "    P_params = [0, 1, 2]\n",
    "    D_params = [0, 1]\n",
    "    Q_params = [0, 1, 2]\n",
    "    m_params = estacional\n",
    "    # crear instancias de configuración\n",
    "    for p in p_params:\n",
    "        for d in d_params:\n",
    "            for q in q_params:\n",
    "                for t in t_params:\n",
    "                    for P in P_params:\n",
    "                        for D in D_params:\n",
    "                            for Q in Q_params:\n",
    "                                for m in m_params:\n",
    "                                    cfg = [(p,d,q), (P,D,Q,m), t]\n",
    "                                    modelos.append(cfg)\n",
    "    return modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alisamiento Exponencial - Holt Winters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediccion_alisamiento_exp(historia, config):\n",
    "    t, d, s, p, b, r = config\n",
    "    # definir el modelo\n",
    "    historia = array(historia)\n",
    "    modelo = ExponentialSmoothing(historia, trend = t, damped = d, seasonal = s, \n",
    "                                  seasonal_periods = p)\n",
    "    # ajustar el modelo con los datos\n",
    "    modelo_ajustado = modelo.fit(optimized = True, use_boxcox = b, remove_bias = r)\n",
    "    # predecir un paso\n",
    "    yhat = modelo_ajustado.predict(len(historia), len(historia))\n",
    "    return yhat[0]\n",
    "\n",
    "def config_alisamiento_exp(estacional = [None]): \n",
    "    modelos = []\n",
    "    # definir las listas de config\n",
    "    t_params = ['add', 'mul', None]\n",
    "    d_params = [True, False] \n",
    "    s_params = ['add', 'mul', None]\n",
    "    p_params = estacional\n",
    "    b_params = [True, False]\n",
    "    r_params = [True, False]\n",
    "    # crear instancias de configuración\n",
    "    for t in t_params:\n",
    "        for d in d_params:\n",
    "            for s in s_params:\n",
    "                for p in p_params:\n",
    "                    for b in b_params:\n",
    "                        for r in r_params:\n",
    "                            cfg = [t,d,s,p,b,r]\n",
    "                            modelos.append(cfg)\n",
    "    return modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caso: Ninguna tendencia - Nacimiento niñas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "series = pd.read_csv('daily-total-female-births.csv', header=0, \n",
    "                     parse_dates = [\"Date\"], index_col = 0)\n",
    "#import seaborn; seaborn.set()\n",
    "series.plot(figsize=(16,10))\n",
    "plt.savefig('nac_fem.png', transparent = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = pd.read_csv('daily-total-female-births.csv', header = 0, index_col = 0)\n",
    "nombre = \"nacimiento-feminas\"\n",
    "encontrar_mejor_solucion(series, nombre, metodo = \"promedio\")\n",
    "encontrar_mejor_solucion(series, nombre, metodo = \"sarima\")\n",
    "encontrar_mejor_solucion(series, nombre, metodo = \"exp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Caso:  Con Tendencia - Ventas Shampoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = pd.read_csv('shampoo.csv', header=0)\n",
    "series[\"Year\"] = [1998] * 12 + [1999] * 12 + [2000] * 12\n",
    "series[\"Month\"] = list(range(1,13)) * 3\n",
    "series[\"Date\"] = series[\"Month\"].apply(str) + \"-\" + series[\"Year\"].apply(str)\n",
    "series['date']  = pd.to_datetime(series[\"Date\"])\n",
    "series = series[[\"date\",\"Sales\"]]\n",
    "series.set_index(['date'],inplace = True)\n",
    "\n",
    "import seaborn; seaborn.set()\n",
    "series.plot(figsize = (16,10))\n",
    "plt.savefig('shampoo.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = pd.read_csv('shampoo.csv', header = 0, index_col = 0)\n",
    "nombre=\"shampoo\"\n",
    "encontrar_mejor_solucion(series, nombre, metodo = \"promedio\")\n",
    "encontrar_mejor_solucion(series, nombre, metodo = \"sarima\")\n",
    "encontrar_mejor_solucion(series, nombre, metodo = \"exp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caso:  Con Estacionalidad - Temperatura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = pd.read_csv('monthly-mean-temp.csv', header = 0, parse_dates = [\"Month\"])\n",
    "series.set_index(['Month'],inplace=True)\n",
    "import seaborn; seaborn.set()\n",
    "series.plot(figsize = (16,10))\n",
    "plt.savefig('temp.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = pd.read_csv('monthly-mean-temp.csv', header = 0, index_col = 0)\n",
    "nombre = \"temp\"\n",
    "encontrar_mejor_solucion(series, nombre, metodo = \"promedio\")\n",
    "encontrar_mejor_solucion(series, nombre, metodo = \"sarima\")\n",
    "encontrar_mejor_solucion(series, nombre, metodo = \"exp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caso: Con Tendencia y con Estacionalidad -  Venta mensual de carros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = pd.read_csv('monthly-car-sales.csv', header = 0,parse_dates = [\"Month\"])\n",
    "series.set_index(['Month'], inplace = True)\n",
    "import seaborn; seaborn.set()\n",
    "series.plot(figsize = (16,10))\n",
    "plt.savefig('cars.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = pd.read_csv('monthly-car-sales.csv', header=0, index_col=0)\n",
    "nombre = \"carros\"\n",
    "encontrar_mejor_solucion(series, nombre, metodo = \"promedio\")\n",
    "encontrar_mejor_solucion(series, nombre, metodo = \"sarima\")\n",
    "encontrar_mejor_solucion(series, nombre, metodo = \"exp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
